{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSI4142 - Data Science\n",
    "\n",
    "## Assignment 3 - Predictive analysis - Regression and Classification\n",
    "\n",
    "Shacha Parker 300235525\n",
    "\n",
    "Callum Frodsham 300199446\n",
    "\n",
    "This part of the assignment takes a dataset and performs an empirical study with a linear regression task.\n",
    "\n",
    "#### Execution of the Notebook\n",
    " \n",
    "FILL THIS IN WHEN FINALIZED\n",
    "\n",
    "### Dataset Information\n",
    "Dataset name: \n",
    "\n",
    "<a href=\"https://www.kaggle.com/datasets/mirichoi0218/insurance\">Medical Cost Personal Datasets</a>\n",
    "<br>\n",
    "Provider: Miri Choi on Kaggle\n",
    "\n",
    "<b>Features</b>\n",
    "\n",
    "    age: age of primary beneficiary - quantitative - continuous\n",
    "\n",
    "    sex: insurance contractor gender, female, male - categorical, ordinal\n",
    "\n",
    "    bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9 - quantitative - continuous\n",
    "\n",
    "    children: Number of children covered by health insurance / Number of dependents - quantitative, discrete\n",
    "\n",
    "    smoker: does the beneficiary smoke - categorical, nominal\n",
    "\n",
    "    region: the beneficiary's residential area in the US: northeast, southeast, southwest, northwest. - categorical, nominal\n",
    "\n",
    "    charges: Individual medical costs billed by health insurance - quantitative, continuous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Load the dataset\n",
    "# CHANGE THIS TO GITHUB RAW\n",
    "data = pd.read_csv('insurance.csv')\n",
    "\n",
    "# output settings for debugging\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "The dataset is already clean. This can be seen with the results of the code cell below: no entries are null, and all values are appropriate. No cleaning is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about the dataframe\n",
    "print(data.info())\n",
    "\n",
    "# Describe the dataframe\n",
    "print(data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "# Check for unique values in categorical columns to identify any unclean data\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "for column in categorical_columns:\n",
    "    print(f\"\\nUnique values in column '{column}':\\n\", data[column].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Feature Encoding\n",
    "Through the get_dummies function, we can create the dataset with all categorical features becoming one-hot vectors. The rest of the features remain as they were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the specified categorical features\n",
    "data = pd.get_dummies(data, columns=['sex', 'smoker', 'region'], drop_first=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA and Outlier detection\n",
    "a. Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison graph for sex_male against sex_female\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(data=data, x='sex_male')\n",
    "plt.title('Count of Male vs Female')\n",
    "plt.xlabel('Sex (0: Female, 1: Male)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Comparison graph for smoker counts\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.countplot(data=data, x='smoker_yes')\n",
    "plt.title('Count of Smokers vs Non-Smokers')\n",
    "plt.xlabel('Smoker (0: No, 1: Yes)')\n",
    "plt.ylabel('Count')\n",
    "plt.show()\n",
    "\n",
    "# Comparison for regions\n",
    "plt.figure(figsize=(10, 5))\n",
    "region_columns = ['region_northeast', 'region_northwest', 'region_southeast', 'region_southwest']\n",
    "region_counts = data[region_columns].sum()\n",
    "sns.barplot(x=region_counts.index, y=region_counts.values)\n",
    "plt.title('Count of Regions')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naturally, outliers don't occur on categorical data like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize numerical features\n",
    "numerical_columns = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "for column in numerical_columns:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(data=data, x=column)\n",
    "    plt.title(f'Box plot of {column}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since feature 'bmi' has only 9 outliers out of the 1000+ entries (0.67%), we can safely remove them without there being a significant statistical impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_outlier_removal = data\n",
    "original = data.shape\n",
    "\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = data['bmi'].quantile(0.25)\n",
    "Q3 = data['bmi'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out the outliers\n",
    "data = data[(data['bmi'] >= lower_bound) & (data['bmi'] <= upper_bound)]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(data=data, x=data['bmi'])\n",
    "plt.title(f'Box plot of BMI after outlier removal')\n",
    "plt.show()\n",
    "\n",
    "print(\"Original data shape:\", original)\n",
    "print(\"Data shape after removing outliers:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 'charges' outliers, it would negatively impact the dataset if all rows with 'charges' outliers were removed. Instead, we'll use  imputation to apply known values over the existing outlier values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile) for 'charges'\n",
    "Q1_charges = data['charges'].quantile(0.25)\n",
    "Q3_charges = data['charges'].quantile(0.75)\n",
    "IQR_charges = Q3_charges - Q1_charges\n",
    "lower_bound_charges = Q1_charges - 1.5 * IQR_charges\n",
    "upper_bound_charges = Q3_charges + 1.5 * IQR_charges\n",
    "\n",
    "# Create D1 by removing rows where 'charges' is an outlier\n",
    "D1 = data[(data['charges'] >= lower_bound_charges) & (data['charges'] <= upper_bound_charges)]\n",
    "\n",
    "# Create D2 by removing 'charges' outliers but keeping the rest of the data\n",
    "D2 = data.copy()\n",
    "D2.loc[(D2['charges'] < lower_bound_charges) | (D2['charges'] > upper_bound_charges), 'charges'] = np.nan\n",
    "\n",
    "# Display the shapes of the original, D1, and D2 datasets\n",
    "print(\"Original data shape:\", data.shape)\n",
    "print(\"D1 data shape (without 'charges' outliers):\", D1.shape)\n",
    "print(\"D2 data shape (with 'charges' outliers removed):\", D2.shape)\n",
    "\n",
    "missing_values_d2 = D2['charges'].isnull().sum()\n",
    "print(\"Missing values in each column of D2:\\n\", missing_values_d2)\n",
    "\n",
    "# Get the indices of missing values in D2\n",
    "missing_indices = D2[D2['charges'].isnull()].index\n",
    "\n",
    "'''\n",
    "# Randomly sample values from D1['charges'] to fill the missing values in D2\n",
    "imputed_values = D1['charges'].sample(n=len(missing_indices), replace=True).values\n",
    "\n",
    "# Impute the missing values in D2\n",
    "D2.loc[missing_indices, 'charges'] = imputed_values\n",
    "\n",
    "missing_values_d2 = D2['charges'].isnull().sum()\n",
    "print(\"Missing values in each column of D2 after RSI:\\n\", missing_values_d2)\n",
    "\n",
    "data = D2\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Separate the features and target variable in the original data\n",
    "X_original = data.drop(columns=['charges'])\n",
    "y_original = data['charges']\n",
    "\n",
    "# Train a linear regression model on the original data\n",
    "imputation_model = LinearRegression()\n",
    "imputation_model.fit(X_original, y_original)\n",
    "\n",
    "# Identify the rows in D2 with missing 'charges' values\n",
    "missing_indices = D2[D2['charges'].isnull()].index\n",
    "\n",
    "# Separate the features for the rows with missing 'charges' in D2\n",
    "X_missing = D2.loc[missing_indices].drop(columns=['charges'])\n",
    "\n",
    "# Predict the missing 'charges' values using the trained model\n",
    "imputed_values = imputation_model.predict(X_missing)\n",
    "\n",
    "# Impute the missing values in D2\n",
    "D2.loc[missing_indices, 'charges'] = imputed_values\n",
    "\n",
    "# Verify that there are no more missing values in 'charges' column of D2\n",
    "missing_values_d2_after_imputation = D2['charges'].isnull().sum()\n",
    "print(\"Missing values in 'charges' column of D2 after imputation:\", missing_values_d2_after_imputation)\n",
    "\n",
    "# Update the main data variable to use D2 with imputed values\n",
    "data = D2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering\n",
    "Before we proceed with feature engineering, we'll create new copies of the dataset with and without outlier removal that will not have the extra features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_without_outlier_removal_or_FE = data_without_outlier_removal\n",
    "data_without_FE = data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the first new feature, we will create the age-bmi column. The age-bmi value is a row's age multiplied by its bmi, which is then normalized by dividing this number by the median age times the median bmi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medianage = data['age'].median()\n",
    "medianbmi = data['bmi'].median()\n",
    "data['age-bmi'] = (data['age'] * data['bmi']) / (medianage * medianbmi)\n",
    "data_without_outlier_removal_with_FE = data_without_outlier_removal\n",
    "data_without_outlier_removal_with_FE['age-bmi'] = (data_without_outlier_removal['age'] * data_without_outlier_removal['bmi']) / (medianage * medianbmi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, we'll create a feature called \"childandsmoker\" which is a boolean value that is true if the row has a positive number of children and 'smoker' is 'yes'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find missing values in data_without_outlier_removal_with_FE\n",
    "missing_values = data_without_outlier_removal_with_FE.isnull().sum()\n",
    "print(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['childandsmoker'] = np.where((data['smoker_yes'] == True) & (data['children'] > 0), True, False)\n",
    "#data_without_outlier_removal_with_FE = data_without_outlier_removal_with_FE.reindex(data.index)\n",
    "data_without_outlier_removal_with_FE['childandsmoker'] = np.where((data_without_outlier_removal_with_FE['smoker_yes'] == True) & (data_without_outlier_removal_with_FE['children'] > 0), True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Renaming these variables to be more legible\n",
    "data_with_both = data\n",
    "data_with_neither = data_without_outlier_removal_or_FE\n",
    "data_with_FE = data_without_outlier_removal_with_FE\n",
    "data_with_OR = data_without_FE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we have:\n",
    "\n",
    "*data_with_both*: the data with both outliers removed and new features engineered.\n",
    "\n",
    "*data_with_neither*: data with neither outliers removed nor feature engineering\n",
    "\n",
    "*data_with_FE*: data including outliers without feature engineering applied\n",
    "\n",
    "*data_with_OR*: data with outliers removed but without feature engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Empirical study"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we split each dataset into train, validation, and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data_with_both dataset\n",
    "data_with_both_train, data_with_both_temp = train_test_split(data_with_both, test_size=0.3, random_state=42)\n",
    "data_with_both_validation, data_with_both_test = train_test_split(data_with_both_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Split the data_with_neither dataset\n",
    "data_with_neither_train, data_with_neither_temp = train_test_split(data_with_neither, test_size=0.3, random_state=42)\n",
    "data_with_neither_validation, data_with_neither_test = train_test_split(data_with_neither_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Split the data_with_FE dataset\n",
    "data_with_FE_train, data_with_FE_temp = train_test_split(data_with_FE, test_size=0.3, random_state=42)\n",
    "data_with_FE_validation, data_with_FE_test = train_test_split(data_with_FE_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Split the data_with_OR dataset\n",
    "data_with_OR_train, data_with_OR_temp = train_test_split(data_with_OR, test_size=0.3, random_state=42)\n",
    "data_with_OR_validation, data_with_OR_test = train_test_split(data_with_OR_temp, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X_train = data_with_neither_train.drop(columns=['charges'])\n",
    "y_train = data_with_neither_train['charges']\n",
    "X_val = data_with_neither_validation.drop(columns=['charges'])\n",
    "y_val = data_with_neither_validation['charges']\n",
    "\n",
    "# Initialize the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Perform 4-fold cross-validation on the training set\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "mse_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "r2_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='r2')\n",
    "\n",
    "# Fit the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate MSE and R2 on the validation set\n",
    "mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "r2_val = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Cross-validated MSE scores:\", -mse_scores)\n",
    "print(\"Cross-validated R2 scores:\", r2_scores)\n",
    "print(\"Mean cross-validated MSE:\", -mse_scores.mean())\n",
    "print(\"Mean cross-validated R2:\", r2_scores.mean())\n",
    "print(\"Validation MSE:\", mse_val)\n",
    "print(\"Validation R2:\", r2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign scores to variables for data with neither\n",
    "mse_scores_neither = mse_scores\n",
    "r2_scores_neither = r2_scores\n",
    "mse_val_neither = mse_val\n",
    "r2_val_neither = r2_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "X_train = data_with_OR_train.drop(columns=['charges'])\n",
    "y_train = data_with_OR_train['charges']\n",
    "X_val = data_with_OR_validation.drop(columns=['charges'])\n",
    "y_val = data_with_OR_validation['charges']\n",
    "\n",
    "# Initialize the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Perform 4-fold cross-validation on the training set\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "mse_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "r2_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='r2')\n",
    "\n",
    "# Fit the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate MSE and R2 on the validation set\n",
    "mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "r2_val = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Cross-validated MSE scores:\", -mse_scores)\n",
    "print(\"Cross-validated R2 scores:\", r2_scores)\n",
    "print(\"Mean cross-validated MSE:\", -mse_scores.mean())\n",
    "print(\"Mean cross-validated R2:\", r2_scores.mean())\n",
    "print(\"Validation MSE:\", mse_val)\n",
    "print(\"Validation R2:\", r2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign scores to variables for data with outliers removed (with_OR)\n",
    "mse_scores_with_OR = mse_scores\n",
    "r2_scores_with_OR = r2_scores\n",
    "mse_val_with_OR = mse_val\n",
    "r2_val_with_OR = r2_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_with_FE_train.drop(columns=['charges'])\n",
    "y_train = data_with_FE_train['charges']\n",
    "X_val = data_with_FE_validation.drop(columns=['charges'])\n",
    "y_val = data_with_FE_validation['charges']\n",
    "\n",
    "# Initialize the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Perform 4-fold cross-validation on the training set\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "mse_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "r2_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='r2')\n",
    "\n",
    "# Fit the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate MSE and R2 on the validation set\n",
    "mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "r2_val = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Cross-validated MSE scores:\", -mse_scores)\n",
    "print(\"Cross-validated R2 scores:\", r2_scores)\n",
    "print(\"Mean cross-validated MSE:\", -mse_scores.mean())\n",
    "print(\"Mean cross-validated R2:\", r2_scores.mean())\n",
    "print(\"Validation MSE:\", mse_val)\n",
    "print(\"Validation R2:\", r2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign scores to variables for data with feature engineering (with_FE)\n",
    "mse_scores_with_FE = mse_scores\n",
    "r2_scores_with_FE = r2_scores\n",
    "mse_val_with_FE = mse_val\n",
    "r2_val_with_FE = r2_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_with_both_train.drop(columns=['charges'])\n",
    "y_train = data_with_both_train['charges']\n",
    "X_val = data_with_both_validation.drop(columns=['charges'])\n",
    "y_val = data_with_both_validation['charges']\n",
    "\n",
    "# Initialize the linear regression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# Perform 4-fold cross-validation on the training set\n",
    "kf = KFold(n_splits=4, shuffle=True, random_state=42)\n",
    "mse_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='neg_mean_squared_error')\n",
    "r2_scores = cross_val_score(model, X_train, y_train, cv=kf, scoring='r2')\n",
    "\n",
    "# Fit the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the validation set\n",
    "y_val_pred = model.predict(X_val)\n",
    "\n",
    "# Calculate MSE and R2 on the validation set\n",
    "mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "r2_val = r2_score(y_val, y_val_pred)\n",
    "\n",
    "# Print the results\n",
    "print(\"Cross-validated MSE scores:\", -mse_scores)\n",
    "print(\"Cross-validated R2 scores:\", r2_scores)\n",
    "print(\"Mean cross-validated MSE:\", -mse_scores.mean())\n",
    "print(\"Mean cross-validated R2:\", r2_scores.mean())\n",
    "print(\"Validation MSE:\", mse_val)\n",
    "print(\"Validation R2:\", r2_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign scores to variables for data with both outliers removed and feature engineering (with_both)\n",
    "mse_scores_with_both = mse_scores\n",
    "r2_scores_with_both = r2_scores\n",
    "mse_val_with_both = mse_val\n",
    "r2_val_with_both = r2_val\n",
    "\n",
    "# Display all result variables\n",
    "print(\"MSE scores for data with neither:\", mse_scores_neither)\n",
    "print(\"R2 scores for data with neither:\", r2_scores_neither)\n",
    "print(\"Validation MSE for data with neither:\", mse_val_neither)\n",
    "print(\"Validation R2 for data with neither:\", r2_val_neither)\n",
    "\n",
    "print(\"\\nMSE scores for data with outliers removed (with_OR):\", mse_scores_with_OR)\n",
    "print(\"R2 scores for data with outliers removed (with_OR):\", r2_scores_with_OR)\n",
    "print(\"Validation MSE for data with outliers removed (with_OR):\", mse_val_with_OR)\n",
    "print(\"Validation R2 for data with outliers removed (with_OR):\", r2_val_with_OR)\n",
    "\n",
    "print(\"\\nMSE scores for data with feature engineering (with_FE):\", mse_scores_with_FE)\n",
    "print(\"R2 scores for data with feature engineering (with_FE):\", r2_scores_with_FE)\n",
    "print(\"Validation MSE for data with feature engineering (with_FE):\", mse_val_with_FE)\n",
    "print(\"Validation R2 for data with feature engineering (with_FE):\", r2_val_with_FE)\n",
    "\n",
    "print(\"\\nMSE scores for data with both outliers removed and feature engineering (with_both):\", mse_scores_with_both)\n",
    "print(\"R2 scores for data with both outliers removed and feature engineering (with_both):\", r2_scores_with_both)\n",
    "print(\"Validation MSE for data with both outliers removed and feature engineering (with_both):\", mse_val_with_both)\n",
    "print(\"Validation R2 for data with both outliers removed and feature engineering (with_both):\", r2_val_with_both)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
