{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CSI4142 - Data Science\n",
    "\n",
    "## Assignment 3 - Predictive analysis - Regression and Classification\n",
    "\n",
    "Shacha Parker 300235525\n",
    "\n",
    "Callum Frodsham 300199446\n",
    "\n",
    "This part of the assignment takes a dataset and performs an empirical study with a linear regression task.\n",
    "\n",
    "#### Execution of the Notebook\n",
    " \n",
    "FILL THIS IN WHEN FINALIZED\n",
    "\n",
    "### Dataset Information\n",
    "Dataset name: \n",
    "\n",
    "<a href=\"https://www.kaggle.com/datasets/mirichoi0218/insurance\">Medical Cost Personal Datasets</a>\n",
    "<br>\n",
    "Provider: Miri Choi on Kaggle\n",
    "\n",
    "<b>Features</b>\n",
    "\n",
    "    age: age of primary beneficiary - quantitative - continuous\n",
    "\n",
    "    sex: insurance contractor gender, female, male - qualitative, ordinal\n",
    "\n",
    "    bmi: Body mass index, providing an understanding of body, weights that are relatively high or low relative to height, objective index of body weight (kg / m ^ 2) using the ratio of height to weight, ideally 18.5 to 24.9 - quantitative - continuous\n",
    "\n",
    "    children: Number of children covered by health insurance / Number of dependents - quantitative, discrete\n",
    "\n",
    "    smoker: does the beneficiary smoke - categorical, nominal\n",
    "\n",
    "    region: the beneficiary's residential area in the US: northeast, southeast, southwest, northwest. - categorical, nominal\n",
    "\n",
    "    charges: Individual medical costs billed by health insurance - quantitative, continuous\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load the dataset\n",
    "# CHANGE THIS TO GITHUB RAW\n",
    "data = pd.read_csv('insurance.csv')\n",
    "\n",
    "# output settings for debugging\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.width', None)\n",
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "The dataset is already clean. This can be seen with the results of the code cell below: no entries are null, and all values are appropriate. No cleaning is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display information about the dataframe\n",
    "print(data.info())\n",
    "\n",
    "# Describe the dataframe\n",
    "print(data.describe())\n",
    "\n",
    "# Check for missing values\n",
    "missing_values = data.isnull().sum()\n",
    "print(\"Missing values in each column:\\n\", missing_values)\n",
    "\n",
    "# Check for unique values in categorical columns to identify any unclean data\n",
    "categorical_columns = data.select_dtypes(include=['object']).columns\n",
    "for column in categorical_columns:\n",
    "    print(f\"\\nUnique values in column '{column}':\\n\", data[column].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Feature Encoding\n",
    "Through the get_dummies function, we can create the dataset with all numerical features becoming one-hot vectors. The rest of the features remain as they were."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(data.head(), \"\\n\")\n",
    "# One-hot encode the specified features\n",
    "data_onehot = pd.get_dummies(data, columns=['bmi', 'charges'])\n",
    "print(data_onehot.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA and Outlier detection\n",
    "a. Outlier detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize categorical features\n",
    "for column in categorical_columns:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.countplot(data=data, x=column)\n",
    "    plt.title(f'Distribution of {column}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It doesn't seem like outliers occur on categorical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize numerical features\n",
    "numerical_columns = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "for column in numerical_columns:\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.boxplot(data=data, x=column)\n",
    "    plt.title(f'Box plot of {column}')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since feature 'bmi' has only 9 outliers out of the 1000+ entries (0.67%), we can safely remove them without there being a significant statistical impact."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = data.shape\n",
    "\n",
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile)\n",
    "Q1 = data['bmi'].quantile(0.25)\n",
    "Q3 = data['bmi'].quantile(0.75)\n",
    "\n",
    "IQR = Q3 - Q1\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter out the outliers\n",
    "data = data[(data['bmi'] >= lower_bound) & (data['bmi'] <= upper_bound)]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "sns.boxplot(data=data, x=data['bmi'])\n",
    "plt.title(f'Box plot of BMI after outlier removal')\n",
    "plt.show()\n",
    "\n",
    "print(\"Original data shape:\", original)\n",
    "print(\"Data shape after removing outliers:\", data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the 'charges' outliers, it would negatively impact the dataset if all rows with 'charges' outliers were removed. Instead, we'll use random sample imputation to "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Q1 (25th percentile) and Q3 (75th percentile) for 'charges'\n",
    "Q1_charges = data['charges'].quantile(0.25)\n",
    "Q3_charges = data['charges'].quantile(0.75)\n",
    "IQR_charges = Q3_charges - Q1_charges\n",
    "lower_bound_charges = Q1_charges - 1.5 * IQR_charges\n",
    "upper_bound_charges = Q3_charges + 1.5 * IQR_charges\n",
    "\n",
    "# Create D1 by removing rows where 'charges' is an outlier\n",
    "D1 = data[(data['charges'] >= lower_bound_charges) & (data['charges'] <= upper_bound_charges)]\n",
    "\n",
    "# Create D2 by removing 'charges' outliers but keeping the rest of the data\n",
    "D2 = data.copy()\n",
    "D2.loc[(D2['charges'] < lower_bound_charges) | (D2['charges'] > upper_bound_charges), 'charges'] = np.nan\n",
    "\n",
    "# Display the shapes of the original, D1, and D2 datasets\n",
    "print(\"Original data shape:\", data.shape)\n",
    "print(\"D1 data shape (without 'charges' outliers):\", D1.shape)\n",
    "print(\"D2 data shape (with 'charges' outliers removed):\", D2.shape)\n",
    "\n",
    "missing_values_d2 = D2.isnull().sum()\n",
    "print(\"Missing values in each column of D2:\\n\", missing_values_d2)\n",
    "\n",
    "# Get the indices of missing values in D2\n",
    "missing_indices = D2[D2['charges'].isnull()].index\n",
    "\n",
    "# Randomly sample values from D1['charges'] to fill the missing values in D2\n",
    "imputed_values = D1['charges'].sample(n=len(missing_indices), replace=True).values\n",
    "\n",
    "# Impute the missing values in D2\n",
    "D2.loc[missing_indices, 'charges'] = imputed_values\n",
    "\n",
    "missing_values_d2 = D2.isnull().sum()\n",
    "print(\"Missing values in each column of D2 after RSI:\\n\", missing_values_d2)\n",
    "\n",
    "data = D2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
